{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48bc2ec-9d06-4e5c-b713-0740ed8b844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 342ms/step - accuracy: 0.1259 - loss: 2.7304 - val_accuracy: 0.0294 - val_loss: 2.7682\n",
      "Epoch 2/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 330ms/step - accuracy: 0.1041 - loss: 2.7208 - val_accuracy: 0.0317 - val_loss: 2.7504\n",
      "Epoch 3/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 332ms/step - accuracy: 0.0895 - loss: 2.5340 - val_accuracy: 0.0582 - val_loss: 2.7167\n",
      "Epoch 4/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 331ms/step - accuracy: 0.1711 - loss: 1.9953 - val_accuracy: 0.0628 - val_loss: 2.8050\n",
      "Epoch 5/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 326ms/step - accuracy: 0.2726 - loss: 1.3958 - val_accuracy: 0.0893 - val_loss: 2.8528\n",
      "Epoch 6/10\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 336ms/step - accuracy: 0.4172 - loss: 0.9584 - val_accuracy: 0.0928 - val_loss: 3.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to: C:\\Users\\sagni\\Downloads\\New folder\\personality_estimator_bi_lstm.h5\n",
      "✅ Tokenizer saved to: C:\\Users\\sagni\\Downloads\\New folder\\tokenizer_bi_lstm.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Set paths\n",
    "DATA_PATH = r\"C:\\Users\\sagni\\Downloads\\New folder\\mbti_1.csv\"\n",
    "MODEL_PATH = r\"C:\\Users\\sagni\\Downloads\\New folder\\personality_estimator_bi_lstm.h5\"\n",
    "TOKENIZER_PATH = r\"C:\\Users\\sagni\\Downloads\\New folder\\tokenizer_bi_lstm.joblib\"\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z ]\", \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "df['posts'] = df['posts'].apply(clean_text)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df['type_encoded'] = le.fit_transform(df['type'])\n",
    "y = to_categorical(df['type_encoded'])\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['posts'])\n",
    "X = tokenizer.texts_to_sequences(df['posts'])\n",
    "X = pad_sequences(X, maxlen=300)\n",
    "\n",
    "# Save tokenizer\n",
    "joblib.dump(tokenizer, TOKENIZER_PATH)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(df['type_encoded']), y=df['type_encoded'])\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=300),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.5),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"✅ Model saved to: {MODEL_PATH}\")\n",
    "print(f\"✅ Tokenizer saved to: {TOKENIZER_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30d2b58-124e-4c17-9591-b2d6fafc4e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Enter text for personality prediction (or type 'exit' to quit):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">   I love to spend time thinking about the mysteries of life and enjoy deep conversations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      "🔍 Predicted MBTI Type: ENTP (Confidence: 0.14)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">   i am very sad for my pet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\n",
      "🔍 Predicted MBTI Type: INTJ (Confidence: 0.11)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">   exit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load paths\n",
    "MODEL_PATH = r\"C:\\Users\\sagni\\Downloads\\New folder\\personality_estimator_bi_lstm.h5\"\n",
    "TOKENIZER_PATH = r\"C:\\Users\\sagni\\Downloads\\New folder\\tokenizer_bi_lstm.joblib\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = load_model(MODEL_PATH)\n",
    "tokenizer = joblib.load(TOKENIZER_PATH)\n",
    "labels = ['INFJ','ENTP','INTP','INTJ','ENTJ','ENFJ','INFP','ENFP',\n",
    "          'ISTJ','ISFJ','ESTJ','ESFJ','ISTP','ISFP','ESTP','ESFP']\n",
    "\n",
    "# Text cleaning\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z ]\", \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "# Prediction loop\n",
    "print(\"📝 Enter text for personality prediction (or type 'exit' to quit):\")\n",
    "while True:\n",
    "    text = input(\">  \")\n",
    "    if text.lower() == 'exit':\n",
    "        break\n",
    "    cleaned = clean_text(text)\n",
    "    seq = tokenizer.texts_to_sequences([cleaned])\n",
    "    padded = pad_sequences(seq, maxlen=300)\n",
    "    pred = model.predict(padded)[0]\n",
    "    mbti_type = labels[np.argmax(pred)]\n",
    "    confidence = np.max(pred)\n",
    "    print(f\"\\n🔍 Predicted MBTI Type: {mbti_type} (Confidence: {confidence:.2f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d521ce-f710-4bfd-9ccc-8bd86042267f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
